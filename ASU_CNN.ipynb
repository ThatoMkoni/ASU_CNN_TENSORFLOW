{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V5E1",
      "authorship_tag": "ABX9TyOWJlA4EUgVeFDqOtitohkO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ThatoMkoni/ASU_CNN_TENSORFLOW/blob/main/ASU_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IMOWjGgO5qLb"
      },
      "outputs": [],
      "source": [
        "!pip install -q tensorflow\n",
        "!pip install -q keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/saraalemadi/DroneAudioDataset/archive/refs/heads/master.zip\n",
        "\n",
        "!unzip /content/master.zip"
      ],
      "metadata": {
        "id": "LzkpCkgHj8Of"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras import layers, models\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "tIq9LN5YboEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_wav_mono(filename : str):\n",
        "    file_contents = tf.io.read_file(filename)\n",
        "    # Decode wav (tensors by channels)\n",
        "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)  # type: ignore\n",
        "    wav = tf.squeeze(wav, axis=1)\n",
        "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "    return wav\n",
        "\n",
        "def preprocess(file_path : str, label : str):\n",
        "    wav = load_wav_mono(file_path)\n",
        "    wav = wav[:48000]\n",
        "    zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)  # type: ignore\n",
        "    wav = tf.concat([zero_padding, wav], 0)\n",
        "    spectogram = tf.signal.stft(wav, frame_length=160, frame_step = 16)\n",
        "    spectogram = tf.abs(spectogram)\n",
        "    print(spectogram.shape)\n",
        "    spectogram = tf.expand_dims(spectogram, axis=2)\n",
        "    print(spectogram.shape)\n",
        "    return spectogram, label\n"
      ],
      "metadata": {
        "id": "fd2DxzO8cLfD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ensures reproducibliity as neurons are set at a known seed\n",
        "seed = 7\n",
        "tf.random.set_seed(seed)\n",
        "np.random.seed(seed)\n"
      ],
      "metadata": {
        "id": "MC-E8BgycRaL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "DATASET_PATH = '/content/DroneAudioDataset-master/Binary_Drone_Audio'\n",
        "yes_drone_path = 'yes_drone/*.wav'\n",
        "no_drone_path = 'unknown/*.wav'\n",
        "\n",
        "POS = f'{DATASET_PATH}/{yes_drone_path}'\n",
        "NEG = f'{DATASET_PATH}/{no_drone_path}'\n",
        "pos = tf.data.Dataset.list_files(POS)\n",
        "neg = tf.data.Dataset.list_files(NEG)\n",
        "\n",
        "positives = tf.data.Dataset.zip((pos, tf.data.Dataset.from_tensor_slices(tf.ones(len(pos)))))\n",
        "negatives = tf.data.Dataset.zip((neg, tf.data.Dataset.from_tensor_slices(tf.zeros(len(neg)))))\n"
      ],
      "metadata": {
        "id": "Qptx5kVLcSZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = positives.concatenate(negatives)\n",
        "print(\"No. Wav: \", len(data))\n",
        "data = data.map(preprocess)\n",
        "data = data.cache()\n",
        "data = data.shuffle(3404)\n",
        "data = data.batch(16)\n",
        "data = data.prefetch(4)\n",
        "print(\"Data: \", len(data))\n",
        "\n",
        "train = data.take(32)\n",
        "test = data.skip(32).take(16)\n",
        "\n",
        "samples, labels = train.as_numpy_iterator().next()  # type: ignore\n",
        "print(samples.shape)\n",
        "\n",
        "num_samples = set(int(i.shape[0]) for i in keras.tree.flatten(samples))"
      ],
      "metadata": {
        "id": "0X-Wz2LzcVkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.Sequential(\n",
        "    [\n",
        "        layers.Input(shape=(1491, 257, 1)),\n",
        "        layers.Resizing(1024, 256),\n",
        "\n",
        "        layers.Conv2D(filters=256, kernel_size=(3,3), activation='relu'),\n",
        "        layers.Conv2D(filters=128, kernel_size=(3,3), activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(filters=64, kernel_size=(3,3), activation='relu'),\n",
        "        layers.MaxPooling2D(),\n",
        "        layers.Conv2D(filters=32, kernel_size=(3,3), activation='relu'),\n",
        "\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dropout(0.5),\n",
        "        layers.Dense(1, activation='sigmoid'),\n",
        "    ]\n",
        ")\n",
        "\n",
        "model.compile('adam', loss='BinaryCrossentropy', run_eagerly=True, metrics=[keras.metrics.Recall(), keras.metrics.Precision()])\n",
        "model.summary()\n",
        "\n",
        "hist = model.fit(train, epochs=5, validation_data=test, verbose='auto')\n"
      ],
      "metadata": {
        "id": "xuc7HaYlcaP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Stats\n",
        "plt.title('Loss')\n",
        "plt.plot(hist.history['loss'], 'r')\n",
        "plt.plot(hist.history['val_loss'], 'b')\n",
        "plt.show()\n",
        "\n",
        "plt.title('Precision')\n",
        "plt.plot(hist.history['precision'], 'r')\n",
        "plt.plot(hist.history['val_precision'], 'b')\n",
        "plt.show()\n",
        "\n",
        "plt.title('Recall')\n",
        "plt.plot(hist.history['recall'], 'r')\n",
        "plt.plot(hist.history['val_recall'], 'b')\n",
        "plt.show()\n",
        "\n",
        "print(\"Test Prediction...\")\n",
        "test = model.predict(samples)\n",
        "print(\"Test Prediction result: \", test)"
      ],
      "metadata": {
        "id": "e9naPTmScfxx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}